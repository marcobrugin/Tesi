\chapter{Componenti di una Data Pipeline}\label{cap:Componenti di una Data Pipeline}
\section{Apache Kafka}
\subsection{Introduzione}
\textbf{Apache Kafka} è una piattaforma \gls{open source}{}, da Jay Kreps, Neha Narkhede e Jun Rao presso LinkedIn e successivamente donata alla \gls{Apache Software Foundation}{} nel 2011. (Figura \ref{fig:logo_kafka}).\\
\textbf{Apache Kafka} nasce con la necessità di LinkedIn di gestire grandi quantità di dati in tempo reale.\\ Già nel 2007 
Jay Kreps e il suo team si resero conto che le soluzioni allora attuali, basate su database tradizionali, non erano in grado di gestire 
un carico di lavoro crescente e la complessità del formato dei dati generati da LinkedIn.\\
Dunque per affrontare tale sfida, nel 2010 LinkedIn iniziò a utilizzare \textbf{Apache Kafka} per gestire i dati di log generati dai vari servizi. \\
Tale adozione ha dimostrato nel tempo che \textbf{Apache Kafka} è in grado di gestire carichi di lavoro molto elevati, di scalare facilmente e di garantire un elevato livello di affidabilità nella consegna di messaggi.\\ 
\textbf{Kafka} è sviluppato in Java e Scala e rilasciata sotto licenza Apache 2.0. La versione attuale è la 3.5.1 rilasciata il 21 luglio 2023.\\
\textbf{Kafka} nasce originariamente come \gls{message broker}{} e permette di gestire uno \gls{streaming di eventi}{} in tempo reale. \\ 
In particolare fornisce funzionalità per:
\begin{list}{*}{}
    \item pubblicare e sottoscrivere flussi di eventi, importandoli ed esportandoli da altri sistemi;
    \item archiviare tali flussi in modo affidabile e duraturo;
    \item elabora flussi di eventi in real time o in modo retrospettivo.
\end{list}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{images/componenti/logo_kafka.png}
    \caption{Logo di Apache Kafka}
    \label{fig:logo_kafka}
\end{figure}
\pagebreak
\subsection{Casi d'uso}
\textbf{Apache Kafka} viene ampliamente utilizzato in tutti quelli scenari in cui è richiesto la gestione 
affidabile di grandi quantità di dati in tempo reale.\\
I principali campi di utilizzo di \textbf{Apache Kafka} sono:
\begin{list}{*}
    \item \textbf{messagistica}: \textbf{Apache Kafka} viene particolarmente utilizzato come \gls{message broker}{}, in applicazioni di messaggistica 
    per disaccoppiare la produzione del messaggio dall'elaborazione dello stesso, \textbf{Kafka} rispetto ai tradizionali \gls{message broker}{} offre velocità e \gls{fault tolerance}{};
    \item \item \textbf{elaborazione del flusso dati}: è possibile anche utilizzare \textbf{Kafka} come componente principale per creare \gls{Data Pipeline}{} in cui i dati grezzi,
    provenienti da diverse sorgenti \textbf{Kafka} vengono aggregati, trasformati fino a ottenere un dato elaborato;
    \item \textbf{monitoraggio e analisi}: \textbf{Kafka} può essere utilizzato per raccogliere dati di monitoraggio provenienti da applicazioni, sistemi di controllo o siti web; 
    \item \textbf{archiviazione dei dati}: \textbf{Apache Kafka} può essere utilizzato come sistema di archiviazione dei dati a lungo termine, permettendo così analisi storiche e ripristino di sistemi 
    in caso di guasti;

\end{list}
\subsection{Architettura e funzionamento}
\textbf{Apache Kafka} nasce come sistema distribuito che opera su nodi (Figure \ref{fig:kafka_architecture}), i quali comunicano tramite protocollo o tramite protocollo
\gls{tcp}{} ad alte prestazioni.Data la sua natura distribuita implementa funzionalità di \gls{fault tolerance}{} con possibilità di rimpiazzo dei nodi che hanno avuto un malfunzionamento.\\  
\textbf{Kafka} può essere distribuito e utilizzato in vari modi tra cui \gls{virtual machine}{} e \gls{container}{}, \gls{on-promise}{}, o servizi cloud.\\
In generale \textbf{Apache Kafka} e costituito da due componenti essenziali: server e client.
\subsubsection{server}
\textbf{Kafka} viene eseguito come un cluster di uno o più server, che rivestono diversi ruoli. \\Alcuni svolgono la funzione di \textbf{Kafka Broker}: ricevono i messaggi dai produttori, li archiviano e inviano i messaggi ai rispettivi consumatori, al momento della sottoscrizione.
\\ Altri invece assolvono il compito di \textbf{Kafka Connect}: importano ed esportano i
dati sotto forma di flussi dati, permettendo così  d'interagire con altri sistemi esistenti.
\subsubsection{client}
I \textbf{client} sono un insieme di librerie che consentono di scrivere applicazioni distribuite e microservizi che permettono d'interagire con
il sistema di messaggistica di \textbf{Apache Kafka}, leggendo, scrivendo ed elaborando flussi di messaggi in parallelo, su larga scala e con \gls{fault tolerance}{} anche in caso di
problemi di rete o guasti della macchina.\\
In generale la scelta del client da utilizzare dipende dal linguaggio di programmazione che si vuole utilizzare per sviluppare l'applicazione.
\subsubsection{I replicas}
In \textbf{Apache Kafka} i \textbf{replicas} costituiscono una parte cruciale dell'architettura e permettono di disporre  di più copie dei dati, distribuite su
più \gls{message broker}{}. Tale meccanismo permette di garantire la \gls{fault tolerance}{} e la scalabilità del sistema.\\
Le repliche possono essere utilizzate a livello di partizione. \textbf{Kafka} ne designa una chiamata \textit{Leader}
mentre le altre sono partizioni \textit{follower o in-sync}. Il numero totale di repliche incluso il
leader costituisce \textbf{il fattore di replicazione}. \\
Il leader e responsabile della ricezione e dell’invio
dei dati, per quella partizione, mentre i \textit{follower} ricevono i dati dal leader e li replicano.\\
\subsubsection{Produttori e consumatori}
Il produttore \textbf{Kafka} invia i dati, con una richiesta di deposito,  direttamente al \gls{message broker}{}, \textit{Leader} della partizione. Per velocizzare la ricerca del
\textit{Leader}, tutti i nodi possono rispondere alle richieste dei produttori fornendo \gls{metadati}{} su quali nodi sono presenti i \textit{Leader}, tale informazione consentirà al produttore d'indirizzare in modo
appropriato i messaggi.\\
D'altra parte il consumatore emette una richiesta di recupero di messaggi al \gls{message broker}{} che funge da \textit{Leader} della partizione, specificando il suo offset nel registro dei messaggi.\\
Il \gls{message broker}{} risponde con un messaggio contenente il suo offset nel registro con ogni richiesta e con una parte del registro a partire da quella posizione. \\
Per quanto riguarda l'estrazione e il recupero dei messaggi: i dati vengono inviati al broker dal produttore e prelevati dal \gls{message broker}{} dal consumatore. 
\subsubsection{La struttura dei messaggi}
I messaggi inviati all'interno di \textbf{Apache Kafka} sono composti da una chiave, un valore e un timestamp. \\
Oltre a tali informazioni a ogni messaggio viene associato un \gls{topic}{} o argomento che permette di eseguire operazioni di organizzazione 
e filtraggio dei messaggi.\\
Un messaggio, una volta inviato a un consumatore non viene eliminato dal \gls{topic}{} ma viene mantenuto per un periodo di tempo configurabile attraverso un timeout.\\
I \gls{topic}{} dei rispettivi messaggi vengono partizionati su più nodi per consentire a più consumatori di leggere gli stessi messaggi e permettendo ai client di leggere e scrivere messaggi da/a molti \gls{message broker}{}.\\
Quando un nuovo messaggio viene emesso, quest'ultimo si aggiunge alla rispettiva partizione relativa al \gls{topic}{} e viene assegnato un numero di offset che identifica il messaggio all'interno della partizione.\\
Grazie a tale meccanismo \textbf{Apache Kafka} garantisce che i messaggi vengano letti nell'ordine in cui sono stati scritti.
\subsubsection{Zookeeper}
\textbf{Zookeeper} è un prodotto \gls{open source}{} che si occupa della sincronizzazione tra i cluster distribuiti di sistemi come \textbf{Apache Kafka}. \\
È progettato per gestire operazioni di sincronizzazione, gestione dello stato e configurazioni nei sistemi distribuiti, garantendo coerenza e affidabilità.\\
Il suo funzionamento si basa sul protocollo Zookeeper Atomic Broadcast (ZAB), che è il cuore del servizio di coordinamento di \textbf{Zookeeper}.\\
Ogni nodo invia a intervalli regolari un messaggio \textit{Keep-Alive} a \textbf{Zookeeper}, informandolo così che è vivo e funzionante. Se entro un tempo prestabilito il messaggio non viene ricevuto si presume che il nodo sia
morto e se era un leader se ne elegge un altro.\\
Inoltre \textbf{Zookeeper} permette di definire dei parametri che consentono di capire quando un nodo è guasto e quanto gli altri nodi, appartenenti a una partizione,  sono in ritardo rispetto al \textit{Leader} in termini di sincronizzazione sull'arrivo dei messaggi.\\
Il parametro \textit{zookeeper.session.timeout.ms}, impostato a 6000 millisecondi per impostazione predefinita, indica che, se il leader non riceve l'evento \textit{Keep-Alive} entro quel periodo temporale, detiene che quel nodo sia guasto.\\
Il parametro \textit{replica.lag.max.messages}, indica la massima differenza consentita tra \textbf{Replica's Offset}e \textbf{Leader's Offset}. Se tale differenza è maggiore di \textit{replica.lag.max.message-1}, il nodo viene considerato in ritardo e viene rimosso dall'elenco dei nodi in sincronizzazione dal leader. \\
Tutti i nodi che sono attivi e sincronizzati formano l' \textbf{In-Sync Replica Set}(\textbf{ISR}).\\
Se tutti i nodi in sincronizzazione hanno memorizzato un messaggio nei rispettivi \gls{log}{}, questo messaggio viene considerato confermato e quindi inviato ai consumatori. \\
In questo modo, un sistema come \textbf{Kafka} garantisce che un messaggio di cui è stato eseguito il \textit{commit} non andrà perso, purché sia presente almeno una replica attiva e sincronizzata, in ogni momento.\\
Un nodo non sincronizzato può ricongiungersi all'\textbf{ISR} se può sincronizzarsi completamente di nuovo, anche se ha perso alcuni dati a causa del suo arresto anomalo.
\subsubsection{Politiche di retentions}
Con \textbf{Retention} in \textbf{Kafka} si intende la possibilità di controllare la dimensione dei registri
degli argomenti ed evitare di superare le dimensioni del disco esistente.\\
La conservazione può essere configurata o controllata in base alla dimensione dei \gls{log}{} o in
base alla durata configurata. Tale configurazione può essere impostata a grana fine o a
grana grossa per ogni argomento o per tutti gli argomenti.
\paragraph{Retention basata sulle dimensione}
Una volta raggiunto il tempo di conservazione configurato per il segmento, quest'ultimo viene contrassegnato per l'eliminazione o la \gls{compattazione}{} in base al criterio di pulizia configurato. Il periodo di conservazione predefinito per i segmenti è di 7 giorni.
I parametri configurabili per la \textbf{Retention} basata sul tempo sono in ordine d'importanza e valutazione sono:
\begin{enumerate}
    \item $log.retention.ms$;
    \item $log.retention.minutes$;
    \item $log.retention.hours$.
\end{enumerate}
Nel momento in cui un parametro di livello di priorità superiore non è impostato si segue la politica di conservazione del parametro di livello di priorità inferiore.\\
\paragraph{Retention basata sulla dimensione}
In questo caso si va configurare la dimensione massima di una struttura di dati di registro per una partizione di argomento. Una volta che la dimensione del registro raggiunge questa dimensione, inizia a rimuovere i segmenti dalla sua fine.\\

I parametri configurabili per la \textbf{Retention} basata dimensione sono in ordine d'importanza e valutazione:
\begin{enumerate}
    \item $log.segment.bytes$: la dimensione massima di un singolo file di registro;
    \item $log.retention.check.interval.ms$: la frequenza in millisecondi con cui la pulizia del registro verifica se un registro è idoneo per l'eliminazione;
    \item $log.segment.delete.delay.ms$: la quantità di tempo da attendere prima di eliminare un file dal file system.
\end{enumerate}


\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{images/componenti/kafka_architetcture.png}
    \caption{Architettura di Apache Kafka}
    \label{fig:kafka_architecture}
\end{figure}

\subsection{Garanzie di funzionamento}
In \textbf{Kafka} esistono produttori e consumatori che producono e sottoscrivono eventi. Gli uni, essendo in un ambiente distribuito,
sono indipendenti l’uno dall’altro. \\
\textbf{Apache Kafka} in tale contesto può fornire una delle seguenti garanzie sulla consegna e ricezione dei messaggi:
\begin{list}{*}
    \item \textbf{at most once}: i messaggi vengono consegnati al consumatore al più una volta. In questo caso, i messaggi possono essere persi, ma non duplicati;
   \item \item  \textbf{at least once}: i messaggi vengono consegnati al consumatore almeno una volta, i messaggi possono essere duplicati, ma non persi;
    \item \textbf{exactly once}: i messaggi vengono consegnati al consumatore esattamente una volta. In questo caso, i messaggi non vengono né persi né duplicati, è la garanzia più costosa ma maggiormente richiesta.
\end{list}
\subsection{Il pattern Publisher-Subscriber}
\textbf{Apache Kafka}, nell'elaborazione dei messaggi, implementa il pattern \textbf{Publisher-Subscriber} (Figura \ref{fig:publisher_subscriber}) che permette di gestire flussi di dati in tempo reale.\\
Il pattern architetturale \textbf{Publisher-Subscriber} è un modello di progettazione software, utilizzato nei sistemi distribuiti, che impiegano una comunicazione asincrona tra i vari componenti.\\
Sebbene vada ad utilizare tecniche già preesistenti come la sottoscrizione e l'accodamento di messaggi, la  chiave di successo di tale pattern è il totale disaccoppiamento delle componenti: i componenti non sono a conoscenza dell'identità e della presenza degli altri.\\
Tale modello è nato dalla necessità del rendere i sistemi ridimensionabili in modo dinamico. Per raggiungere tale obiettivo, lo scambio di messaggi 
tra i due agenti in gioco viene gestito da un intermediario, chiamato \textbf{broker}, che si occupa di ricevere i messaggi dai \textbf{publisher} e di inoltrarli ai \textbf{subscriber}.\\
\subsubsection{Vantaggi}
\begin{itemize}
    \item \textbf{Debole accopiamento tra le componenti}:  rende il sistema più flessibile e modificabile dinamicamente;
    \item \textbf{Elevata scalabilità}: non esiste limite al numero di \textbf{publisher} e \textbf{subscriber} che possano comunicare;
    \item \textbf{Utilizzo della comunicazione ascincrona ad eventi}: non necessità della sincrona degli attori coinvolti nella comunicazione;
    \item \textbf{Indipendente dal protocollo di comunicazione}: è integrabile con qualsiasi protocollo di comunicazione e stack tecnologico.
\end{itemize}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{images/componenti/ps-model.png}
    \caption{Il pattern Publisher-Subscriber}
    \label{fig:publisher_subscriber}
\end{figure}
\pagebreak
\subsection{Even Driven Architecture}
L'\textbf{Even Driven Architecture} è un pattern architetturale basato su eventi: degli agenti, che sono in grado di ricevere tali eventi, agiscono solo nel momento in cui questi ultimi si verificheranno. 
\\Una architettura basato su eventi fornisce una serie di altri vantaggi basati sul disaccoppiamento tra il produttore e il consumatore dell'evento, i quali, nel momento dell'emissione di quest'ultimo non è necessario siano sincroni ma possono andare a sfruttare una comunicazione di tipo asincrona. 
\subsubsection{Apache Kafka e l'architettura EDA}
L'emissione di un evento indica che qualcosa è accaduto e può essere visto come un agglomerato di dati atomico in grado di soddisfare l'evento stesso. \\
Di solito \textbf{Apache Kafka} viene descritto anche come una piattaforma di \gls{streaming di eventi}{} gestisti come flusso continuo di dati. \\Inoltre \textbf{Kafka} memorizza tali dati in modo duraturo per il successivo recupero, analisi o elaborazione in tempo reale.
\\D'altra parte per utilizzare \textbf{Kafka} in un sistema \textbf{EDA} la chiave è andare a sfruttare il disaccopiamento: invece di effettuare un polling continuo di verifica della presenza di nuovi dati, basterà ascoltare il verificarsi di un evento per agire di conseguenza. Inoltre grazie all'approcio sviluppato da \textbf{Kafka} un evento una volta soddisfatto non viene eliminato, ma conservato per un periodo ti tempo predeterminato, pertanto un evento potrà essere letto da più consumatori e potrà essere utilizzato per soddisfare una varietà di richieste, fino alla scadenza del suo periodo di conservazione. \\
\pagebreak
\section{Apache Druid}
\textbf{Apache Druid} (Figura \ref{fig:logo_druid}) è uno strumento \gls{open source}{} di analisi \gls{olap}{} progettato per analizzare e gestire grandi moli di dati in tempo reale, in modo scalabile. \\
Il progetto su cui si basa \textbf{Apache Druid} è stato sviluppato a partire dal 2011 da Metamarkets, una società di analisi dei dati in tempo reale per il settore pubblicitario,
da parte di Gian Merlino, Eric Tschetter e Fangjin Yang.\\
L'obiettivo iniziale era quello di creare un sistema in grado di analizzare, in tempo reale, grandi quantità di dati per fornire ai clienti 
informazioni sulle campagne pubblicitarie.\\
Purtroppo le tecnologie allora esistenti non erano in grado di soddisfare le esigenze di Metamarkets, pertanto il team di sviluppo decise di creare un nuovo sistema che potesse soddisfare le loro esigenze, che ha preso il nome di \textbf{Druid}.\\
\textbf{Druid} nasce per gestire dati di tipo evento, come strumento di \gls{log}{}, dati di transazione e molti altri. \\
Nel 2012, Metamarkets ha rilasciato \textbf{Druid}{} come progetto \gls{open source}{} su GitHub, permettendo così alla comunità di contribuire e sviluppare ulteriormente la piattaforma. Nel 2015, \textbf{Druid} è diventato un progetto \gls{open source}{} ufficiale sotto l'autorità della \gls{Apache Software Foundation}{}.\\ 
\textbf{Apache Druid} è comunemente utilizzato come back-end per le GUI di applicazioni analitiche o
per \gls{api}{} altamente simultanee che richiedono aggregazioni veloci. \\
\textbf{Druid} è sviluppato in Java e Scala, rilasciato sotto licenza Apache 2.0. \\La versione attuale è la 27.0.0 rilasciata il 10 agosto 2023.\\
\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{images/componenti/logo_druid.png}
    \caption{Logo di Apache Druid}
    \label{fig:logo_druid}
\end{figure}
\subsection{Casi d'uso}
\textbf{Apache Druid} viene utilizzato in tutti quegli scenari in cui è necessario analizzare grandi quantità di dati in tempo reale, in modo scalabile, con \gls{fault tolerance}{} e con la possibilità di effettuare query complesse ad alta efficienza.\\  
I principali campi di utilizzo di \textbf{Apache Druid} sono:
\begin{list}{*}
    \item \textbf{analisi dati in real-time e applicazioni dati}: \textbf{Apache Druid} viene ampliamente impiegato sistemi di acquisizione dati in
    tempo reale, query rapide e tempo di attività. \textbf{Druid} viene utilizzato per alimentare GUI
    di applicazioni analitiche o per \gls{api}{} simultanee che necessitano di aggregazioni veloci, i migliori risultati 
    vengono ottenuti nell'analisi di dati di tipo evento;
    \pagebreak
    \item \item \textbf{elaborazione di metriche}: \textbf{Apache Druid} viene spesso utilizzato per effettuare misurazioni sul coinvolgimento degli
    utenti e il monitoraggio dei dati di test, calcolando metriche, conteggi finalizzati a elaborare tendenze su grandi moli di dati;
    \item \textbf{operazioni \gls{olap}{}}: \textbf{Apache Druid} viene utilizzato per accelerare l’esecuzione di query su grandi moli di dati e potenziare le applicazioni; è progettato per un’elevata concorrenza e query in meno di un secondo, alimentando
    l’esplorazione interattiva dei dati attraverso un’interfaccia utente.
\end{list}
\subsection{Architettura e funzionamento}
\textbf{Apache Druid} include molteplici configurazione sia su singolo nodo, che distribuito su un \gls{cluster}{}.\\
Le distribuzioni su singolo nodo sono ormai poco utilizzate, ma esistono altre configurazioni pensate per macchine con bassa disponibilità di 
CPU e memoria, pensate appositamente piccoli \gls{container}{} \gls{Docker}{}. 
\subsubsection{Distribuzione su cluster}
\textbf{Apache Druid} nasce come sistema distribuito, scalabile, tollerante ai guasti, compatibile con il cloud. \\
Inoltre una architettura di questo tipo un malfunzionamento di una componente non influisce immediatamente sulle altre.\\

In generale un \gls{cluster}{} di \textbf{Apache Druid} ospita i seguenti server: 
\begin{list}{*}
    \item \textbf{i server principali}: sono responsabili della gestione dei \gls{metadati}{} e delle esigenze di coordinamento del \gls{cluster}{}, possono essere collocati insieme sullo stesso server;
    \item \item \textbf{i server dati}: finalizzati a  gestire i dati effettivi all'interno \gls{cluster}{}, traggono grandi vantaggi da CPU, RAM e SSD;
    \item  \textbf{i server d'interrogazione}: chiamati anche \textbf{Druid Broker}, accettano le richieste e le distribuiscono al resto del cluster.
\end{list}
\paragraph{I server principali} o \textbf{Master} gestiscono l’\gls{injection}{} e la disponibilità dei dati: sono i responsabile dell’avvio
di nuovi operazioni di \gls{injection}{} e del coordinamento della disponibilità dei dati sui \textbf{Data server}.\\
Ogni server mantiene una connessione con a un \textbf{Zookeeper} per le informazioni sul \gls{cluster}{} corrente.
I server \textbf{Master} eseguono al loro interno i seguenti processi:
\subparagraph{I Coordinator} hanno il compito di gestire la disponibilità dei dati dei \gls{cluster}{}, comunicano
agli \textbf{Historical} di caricare o rilasciare segmenti in base alle configurazioni, sono i 
responsabili del caricamento di nuovi segmenti, dell’eliminazione di segmenti obsoleti, della
garanzia che i segmenti siano replicati (caricati su più nodi \textbf{Historical} diversi) un
numero corretto  di volte e sia presente un bilanciamento dei segmenti
tra \textbf{Historical} per mantenere quest’ultimo caricato uniformemente.Il \textbf{Coordinator} ha anche una connessione a un database
contenente l’elenco dei segmenti utilizzati. 
\subparagraph{Gli Overlord} sono i responsabili dell’accettazione delle attività, del coordinamento della distribuzione delle
attività, della restituzione degli stati ai
chiamanti. Possono essere eseguiti sia in modalità locale che su server dedicato. Gli \textbf{Overlord} hanno anche il compito di 
creare i \textbf{Peon} per l'esecuzione delle attività. 
\paragraph{I Server dati} eseguono le attività d'acquisizione e archiviazione dei dati interrogabili.
I server \textbf{dati} eseguono al loro interno i seguenti processi:
\subparagraph{Gli Historical} hanno il compito di copiare o estrarre i file di segmento dal \textbf{Deep Storage} al disco locale in un’area
chiamata $segment cache$ e di rispondere alle \textbf{query} su tali segmenti.
Il \textbf{Coordinator} controlla l’assegnazione dei segmenti agli \textbf{Historical} e il bilanciamento dei segmenti assegnati
a questi ultimi.\\ 
Gli \textbf{Historical} non comunicano direttamente tra loro, ne comunicano direttamente con il \textbf{Coordinator}. 
\subparagraph{I MiddleManager} 
hanno il compito di eseguire le attività di \gls{injection}{} e di indicizzazione dei dati.\\
Sono i responsabili dell'inserimento di nuovi dati all'interno del \gls{cluster}{}, della lettura di dati da fonti esterne e della pubblicazione di 
nuovi segmenti.\\
\subparagraph{I  Peon} sono i motori di esecuzione delle attività generate dai processi \textbf{MiddleManager}. \\
Ogni \textbf{Peon} viene eseguito su una JVM separata ed è responsabile dell’esecuzione di una singola attività. 
Tutti i Peon che sono stati generati da un processo \textbf{MiddleManager} vengono eseguiti sullo stesso nodo.
\paragraph{I Server d'interrogazione} o Server \textbf{query} forniscono la funzionalità d'interazione con gli utenti, instradando le richieste  
ai \textbf{server dati} o ad altri \textbf{server query}, per la loro esecuzione. \\
I server \textbf{query} eseguono al loro interno i seguenti processi:
\subparagraph{I Broker} sono i processi a cui instradare le query, analizzano i \gls{metadati}{} forniti
da \textbf{Zookeeper}, comprendono dove ricavare i dati necessari per elaborare i risultati delle query ed 
infine uniscono tutti i risultati elaborati per fornire un’unica risposta alla richiesta.\\
\subparagraph{I Router} sono i processi che hanno il compito di instradare le query a diversi processi \textbf{Broker}. Le query
vengono instradate in base alle regole di caricamento dei segmenti che vengono applicate.
Tale configurazione fornisce l’isolamento delle singole query, anche nel caso in cui si voglia applicare 
una priorità di esecuzione a determinate query.\\
\begin{figure}[h]   
    \centering
    \includegraphics[width=0.9\textwidth]{images/componenti/druid_architectcture.png}
    \caption{Architettura di Apache Druid}
    \label{fig:druid_architecture}
\end{figure}
\pagebreak
\section{Streaming Data Pipelines}
\newpage
\pagestyle{empty}
\null % o \mbox{} o \phantom{X}
\newpage