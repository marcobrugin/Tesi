\chapter{Componenti di una Data Pipeline}\label{cap:Componenti di una Data Pipeline}
\section{Apache Kafka}
\subsection{Introduzione}
\textbf{Apache Kafka} è una piattaforma \gls{open source}{}, da Jay Kreps, Neha Narkhede e Jun Rao presso LinkedIn e successivamente donata alla \gls{Apache Software Foundation}{} nel 2011. (Figura \ref{fig:logo_kafka}).\\
\textbf{Apache Kafka} nasce con la necessità di LinkedIn di gestire grandi quantità di dati in tempo reale.\\ Già nel 2007 
Jay Kreps e il suo team si resero conto che le soluzioni allora attuali, basate su database tradizionali, non erano in grado di gestire 
un carico di lavoro crescente e la complessità del formato dei dati generati da LinkedIn.\\
Dunque per affrontare tale sfida, nel 2010 LinkedIn iniziò a utilizzare \textbf{Apache Kafka} per gestire i dati di \gls{log}{} generati dai vari servizi. \\
Tale adozione ha dimostrato nel tempo che \textbf{Apache Kafka} è in grado di gestire carichi di lavoro molto elevati, di scalare facilmente e di garantire un elevato livello di affidabilità nella consegna di messaggi.\\ 
\textbf{Kafka} è sviluppato in Java e Scala e rilasciata sotto licenza Apache 2.0. La versione attuale è la 3.5.1 rilasciata il 21 luglio 2023.\\
\textbf{Kafka} nasce originariamente come \gls{message broker}{} e permette di gestire uno \gls{streaming di eventi}{} in tempo reale. \\ 
In particolare fornisce funzionalità per:
\begin{list}{*}{}
    \item pubblicare e sottoscrivere flussi di eventi, importandoli ed esportandoli da altri sistemi;
    \item archiviare tali flussi in modo affidabile e duraturo;
    \item elabora flussi di eventi in real time o in modo retrospettivo.
\end{list}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{images/componenti/logo_kafka.png}
    \caption{Logo di Apache Kafka}
    \label{fig:logo_kafka}
\end{figure}
\pagebreak
\subsection{Casi d'uso}
\textbf{Apache Kafka} viene ampliamente utilizzato in tutti quelli scenari in cui è richiesto la gestione 
affidabile di grandi quantità di dati in tempo reale.\\
I principali campi di utilizzo di \textbf{Apache Kafka} sono:
\begin{list}{*}
    \item \textbf{messagistica}: \textbf{Apache Kafka} viene particolarmente utilizzato come \gls{message broker}{}, in applicazioni di messaggistica 
    per disaccoppiare la produzione del messaggio dall'elaborazione dello stesso, \textbf{Kafka} rispetto ai tradizionali \gls{message broker}{} offre velocità e \gls{fault tolerance}{};
    \item \item \textbf{elaborazione del flusso dati}: è possibile anche utilizzare \textbf{Kafka} come componente principale per creare \gls{Data Pipeline}{} in cui i dati grezzi,
    provenienti da diverse sorgenti \textbf{Kafka} vengono aggregati, trasformati fino a ottenere un dato elaborato;
    \item \textbf{monitoraggio e analisi}: \textbf{Kafka} può essere utilizzato per raccogliere dati di monitoraggio provenienti da applicazioni, sistemi di controllo o siti web; 
    \item \textbf{archiviazione dei dati}: \textbf{Apache Kafka} può essere utilizzato come sistema di archiviazione dei dati a lungo termine, permettendo così analisi storiche e ripristino di sistemi 
    in caso di guasti;

\end{list}
\subsection{Architettura e funzionamento}
\textbf{Apache Kafka} nasce come sistema distribuito che opera su nodi, i quali comunicano tramite protocollo
\gls{tcp}{} ad alte prestazioni. Data la sua natura distribuita implementa funzionalità di \gls{fault tolerance}{} con possibilità di rimpiazzo dei nodi che hanno avuto un malfunzionamento.\\  
\textbf{Kafka} può essere distribuito e utilizzato in vari modi tra cui \gls{virtual machine}{} e \gls{container}{}, \gls{on-promise}{}, o servizi cloud.\\
In generale \textbf{Apache Kafka} è costituito da due componenti essenziali: server e client.
\subsubsection{Server}
\textbf{Kafka} viene eseguito come un cluster di uno o più server, che rivestono diversi ruoli. \\Alcuni svolgono la funzione di \textbf{Kafka Broker}: ricevono i messaggi dai produttori, li archiviano e inviano i messaggi ai rispettivi consumatori, al momento della sottoscrizione.
\\ Altri invece assolvono il compito di \textbf{Kafka Connect}: importano ed esportano i
dati sotto forma di flussi dati, permettendo così  d'interagire con altri sistemi esistenti.
\subsubsection{Client}
I \textbf{client} sono un insieme di librerie che consentono di scrivere applicazioni distribuite e microservizi che permettono d'interagire con
il sistema di messaggistica di \textbf{Apache Kafka}, leggendo, scrivendo ed elaborando flussi di messaggi in parallelo, su larga scala e con \gls{fault tolerance}{} anche in caso di
problemi di rete o guasti della macchina.\\
In generale la scelta del client da utilizzare dipende dal linguaggio di programmazione che si vuole utilizzare per sviluppare l'applicazione.
\subsubsection{I replicas}
In \textbf{Apache Kafka} i \textbf{replicas} costituiscono una parte cruciale dell'architettura e permettono di disporre  di più copie dei dati, distribuite su
più \gls{message broker}{}. Tale meccanismo permette di garantire la \gls{fault tolerance}{} e la scalabilità del sistema.\\
Le repliche possono essere utilizzate a livello di partizione. \textbf{Kafka} ne designa una chiamata \textit{Leader}
mentre le altre sono partizioni \textit{follower o in-sync}. Il numero totale di repliche incluso il
leader costituisce \textbf{il fattore di replicazione}. \\
Il leader e responsabile della ricezione e dell’invio
dei dati, per quella partizione, mentre i \textit{follower} ricevono i dati dal leader e li replicano.\\
\subsubsection{Produttori e consumatori}
Il produttore \textbf{Kafka} invia i dati, con una richiesta di deposito,  direttamente al \gls{message broker}{}, \textit{Leader} della partizione. Per velocizzare la ricerca del
\textit{Leader}, tutti i nodi possono rispondere alle richieste dei produttori fornendo \gls{metadati}{} su quali nodi sono presenti i \textit{Leader}, tale informazione consentirà al produttore d'indirizzare in modo
appropriato i messaggi.\\
D'altra parte il consumatore emette una richiesta di recupero di messaggi al \gls{message broker}{} che funge da \textit{Leader} della partizione, specificando il suo offset nel registro dei messaggi.\\
Il \gls{message broker}{} risponde con un messaggio contenente il suo offset nel registro con ogni richiesta e con una parte del registro a partire da quella posizione (Figura \ref{fig:kafka_architecture}).
\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{images/componenti/kafka_architetcture.png}
    \caption{Architettura di Apache Kafka}
    \label{fig:kafka_architecture}
\end{figure}
\subsubsection{La struttura dei messaggi}
I messaggi inviati all'interno di \textbf{Apache Kafka} sono composti da una chiave, un valore e un timestamp. \\
Oltre a tali informazioni a ogni messaggio viene associato un \gls{topic}{} o argomento che permette di eseguire operazioni di organizzazione 
e filtraggio dei messaggi.\\
Un messaggio, una volta inviato a un consumatore non viene eliminato dal \gls{topic}{} ma viene mantenuto per un periodo di tempo configurabile attraverso un timeout.\\
I \gls{topic}{} dei rispettivi messaggi vengono partizionati su più nodi per consentire a più consumatori di leggere gli stessi messaggi e permettere ai client di leggere e scrivere messaggi da/a molti \gls{message broker}{}.\\
Quando un nuovo messaggio viene emesso, quest'ultimo si aggiunge alla rispettiva partizione relativa al \gls{topic}{} e viene assegnato un numero di offset che identifica il messaggio all'interno della partizione.\\
Grazie a tale meccanismo \textbf{Apache Kafka} garantisce che i messaggi vengano letti nell'ordine in cui sono stati scritti.
\subsubsection{Zookeeper}
\textbf{Zookeeper} è un prodotto \gls{open source}{} che si occupa della sincronizzazione tra i cluster distribuiti di sistemi come \textbf{Apache Kafka}. \\
È progettato per gestire operazioni di sincronizzazione, gestione dello stato e configurazioni nei sistemi distribuiti, garantendo coerenza e affidabilità.\\
Il suo funzionamento si basa sul protocollo Zookeeper Atomic Broadcast (ZAB), che è il cuore del servizio di coordinamento di \textbf{Zookeeper}.\\
Ogni nodo invia a intervalli regolari un messaggio \textit{Keep-Alive} a \textbf{Zookeeper}, informandolo così che è vivo e funzionante. Se entro un tempo prestabilito il messaggio non viene ricevuto si presume che il nodo sia
morto e se era un leader se ne elegge un altro.\\
Inoltre \textbf{Zookeeper} permette di definire dei parametri che consentono di capire quando un nodo è guasto e quanto gli altri nodi, appartenenti a una partizione,  sono in ritardo rispetto al \textit{Leader} in termini di sincronizzazione sull'arrivo dei messaggi.\\
Il parametro \textit{zookeeper.session.timeout.ms}, impostato a 6000 millisecondi per impostazione predefinita, indica che, se il leader non riceve l'evento \textit{Keep-Alive} entro quel periodo temporale, detrmina che quel nodo sia guasto.\\
Il parametro \textit{replica.lag.max.messages}, indica la massima differenza consentita tra \textbf{Replica's Offset}e \textbf{Leader's Offset}. Se tale differenza è maggiore di \textit{replica.lag.max.message-1}, il nodo viene considerato in ritardo e viene rimosso dall'elenco dei nodi in sincronizzazione dal leader. \\
Tutti i nodi che sono attivi e sincronizzati formano l' \textbf{In-Sync Replica Set}(\textbf{ISR}).\\
Se tutti i nodi in sincronizzazione hanno memorizzato un messaggio nei rispettivi \gls{log}{}, questo messaggio viene considerato confermato e quindi inviato ai consumatori. \\
In questo modo, un sistema come \textbf{Kafka} garantisce che un messaggio di cui è stato eseguito il \textit{commit} non andrà perso, purché sia presente almeno una replica attiva e sincronizzata, in ogni momento.\\
Un nodo non sincronizzato può ricongiungersi all'\textbf{ISR} se può sincronizzarsi completamente di nuovo, anche se ha perso alcuni dati a causa del suo arresto anomalo.
\pagebreak
\subsubsection{Politiche di retention}
Con \textbf{retention} in \textbf{Kafka} si intende la possibilità di controllare la dimensione dei registri
degli argomenti ed evitare di superare le dimensioni del disco esistente.\\
La conservazione può essere configurata o controllata in base alla dimensione dei \gls{log}{} o in
base alla durata configurata. Tale configurazione può essere impostata a grana fine o a
grana grossa per ogni argomento o per tutti gli argomenti.
\paragraph{Retention basata sulle dimensione}
Una volta raggiunto il tempo di conservazione configurato per il segmento, quest'ultimo viene contrassegnato per l'eliminazione o la \gls{compattazione}{} in base al criterio di pulizia configurato. Il periodo di conservazione predefinito per i segmenti è di 7 giorni.
I parametri configurabili per la \textbf{Retention} basata sul tempo sono in ordine d'importanza e valutazione sono:
\begin{enumerate}
    \item $log.retention.ms$;
    \item $log.retention.minutes$;
    \item $log.retention.hours$.
\end{enumerate}
Nel momento in cui un parametro di livello di priorità superiore non è impostato si segue la politica di conservazione del parametro di livello di priorità inferiore.\\
\paragraph{Retention basata sulla dimensione}
In questo caso si  configura la dimensione massima di una struttura di dati di registro per una partizione di argomento. Una volta che la dimensione del registro raggiunge questa dimensione, inizia a rimuovere i segmenti dalla sua fine.\\

I parametri configurabili per la \textbf{Retention} basata dimensione sono in ordine d'importanza e valutazione:
\begin{enumerate}
    \item $log.segment.bytes$: la dimensione massima di un singolo file di registro;
    \item $log.retention.check.interval.ms$: la frequenza in millisecondi con cui la pulizia del registro verifica se un registro è idoneo per l'eliminazione;
    \item $log.segment.delete.delay.ms$: la quantità di tempo da attendere prima di eliminare un file dal file system.
\end{enumerate}

\subsection{Garanzie di funzionamento}
In \textbf{Kafka} esistono produttori e consumatori che producono e sottoscrivono eventi. Gli uni, essendo in un ambiente distribuito,
sono indipendenti l’uno dall’altro. \\
\textbf{Apache Kafka} in tale contesto può fornire una delle seguenti garanzie sulla consegna e ricezione dei messaggi:
\begin{list}{*}
    \item \textbf{at most once}: i messaggi vengono consegnati al consumatore al più una volta. In questo caso, i messaggi possono essere persi, ma non duplicati;
   \item \item  \textbf{at least once}: i messaggi vengono consegnati al consumatore almeno una volta, i messaggi possono essere duplicati, ma non persi;
    \item \textbf{exactly once}: i messaggi vengono consegnati al consumatore esattamente una volta. In questo caso, i messaggi non vengono né persi né duplicati, è la garanzia più costosa ma maggiormente richiesta.
\end{list}
\subsection{Il pattern Publisher-Subscriber}
\textbf{Apache Kafka}, nell'elaborazione dei messaggi, implementa il pattern \textbf{Publisher-Subscriber} (Figura \ref{fig:publisher_subscriber}) che permette di gestire flussi di dati in tempo reale.\\
Il pattern architetturale \textbf{Publisher-Subscriber} è un modello di progettazione software, utilizzato nei sistemi distribuiti, che impiegano una comunicazione asincrona tra i vari componenti.\\
Sebbene vada ad utilizzare tecniche già preesistenti come la sottoscrizione e l'accodamento di messaggi, la  chiave di successo di tale pattern è il totale disaccoppiamento delle componenti: i componenti non sono a conoscenza dell'identità e della presenza degli altri.\\
Tale modello è nato dalla necessità del rendere i sistemi ridimensionabili in modo dinamico. Per raggiungere tale obiettivo, lo scambio di messaggi 
tra i due agenti in gioco viene gestito da un intermediario, chiamato \textbf{broker}, che si occupa di ricevere i messaggi dai \textbf{publisher} e di inoltrarli ai \textbf{subscriber}.\\
\subsubsection{Vantaggi}
\begin{itemize}
    \item \textbf{Debole accoppiamento tra le componenti}:  rende il sistema più flessibile e modificabile dinamicamente;
    \item \textbf{Elevata scalabilità}: non esiste limite al numero di \textbf{publisher} e \textbf{subscriber} che possano comunicare;
    \item \textbf{Utilizzo della comunicazione asincrona ad eventi}: non necessità della sincronazzazione degli attori coinvolti nella comunicazione;
    \item \textbf{Indipendente dal protocollo di comunicazione}: è integrabile con qualsiasi protocollo di comunicazione e stack tecnologico.
\end{itemize}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{images/componenti/ps-model.png}
    \caption{Il pattern Publisher-Subscriber}
    \label{fig:publisher_subscriber}
\end{figure}
\subsection{Alta affidabilità}\label{sec:alta_affidabilita}
Nel contesto si \textbf{Apache Kafka} con il termine di \textbf{alta affidabilità} ci si riferisce alla capacità di un sistema di gestire in modo
robusto e coerente la ricezione, l'elaborazione e consegna dei messaggi anche in caso di guasti o malfunzionamenti.\\
L'alta affidabilità fornisce anche la garanzia che i flussi di messaggi non vengano persi o corrotti.
\subsubsection{Numero dispari di nodi}\label{sec:numero_dispari_nodi}
\textbf{Apache Kafka} per garantire l'alta affidabilità utilizza le $repliche$: copie dei dati distribuite su più nodi.\\
Infatti nel caso in cui ci trovi nella condizione di prendere decisioni di consenso, eleggere $Leader$ o eseguire altre operazioni di coordinamento, \textbf{Kafka} richiede il consenso 
da parte della maggioranza dei nodi. Pertanto per raggiungerla sempre è buona pratica utilizzare un numero di nodi dispari (3,5,7,9,...), per evitare situazioni di stallo.\\

\subsection{Even Driven Architecture}
L'\textbf{Even Driven Architecture} è un pattern architetturale basato su eventi: degli agenti, che sono in grado di ricevere tali eventi, agiscono solo nel momento in cui questi ultimi si verificheranno. 
\\Una architettura basato su eventi fornisce una serie di altri vantaggi basati sul disaccoppiamento tra il produttore e il consumatore dell'evento, i quali, nel momento dell'emissione di quest'ultimo non è necessario siano sincroni ma possono andare a sfruttare una comunicazione di tipo asincrona. 
\subsubsection{Apache Kafka e l'architettura EDA}
L'emissione di un evento indica che qualcosa è accaduto e può essere visto come un agglomerato di dati atomico in grado di soddisfare l'evento stesso. \\
Di solito \textbf{Apache Kafka} viene descritto anche come una piattaforma di \gls{streaming di eventi}{} gestisti come flusso continuo di dati. \\Inoltre \textbf{Kafka} memorizza tali dati in modo duraturo per il successivo recupero, analisi o elaborazione in tempo reale.
\\D'altra parte per utilizzare \textbf{Kafka} in un sistema \gls{eda}{} la chiave è andare a sfruttare il disaccoppiamento: invece di effettuare un polling continuo di verifica della presenza di nuovi dati, basterà ascoltare il verificarsi di un evento per agire di conseguenza. \\Inoltre grazie all'approccio sviluppato da \textbf{Kafka} un evento una volta soddisfatto, non viene eliminato, ma conservato per un periodo di tempo predeterminato, pertanto un evento potrà essere letto da più consumatori e potrà essere utilizzato per soddisfare una varietà di richieste, fino alla scadenza del suo periodo di conservazione. \\
\pagebreak
\section{Apache Druid}
\textbf{Apache Druid} (Figura \ref{fig:logo_druid}) è uno strumento \gls{open source}{} di analisi \gls{olap}{} progettato per analizzare e gestire grandi moli di dati in tempo reale, in modo scalabile. \\
Il progetto su cui si basa \textbf{Apache Druid} è stato sviluppato a partire dal 2011 da Metamarkets, una società di analisi dei dati in tempo reale per il settore pubblicitario,
da parte di Gian Merlino, Eric Tschetter e Fangjin Yang.\\
L'obiettivo iniziale era quello di creare un sistema in grado di analizzare, in tempo reale, grandi quantità di dati per fornire ai clienti 
informazioni sulle campagne pubblicitarie.\\
Purtroppo le tecnologie allora esistenti non erano in grado di soddisfare le esigenze di Metamarkets, pertanto il team di sviluppo decise di creare un nuovo sistema che potesse soddisfare le loro esigenze, che ha preso il nome di \textbf{Druid}.\\
\textbf{Druid} nasce per gestire dati di tipo evento, come strumento di \gls{log}{}, dati di transazione e molti altri. \\
Nel 2012, Metamarkets ha rilasciato \textbf{Druid}{} come progetto \gls{open source}{} su GitHub, permettendo così alla comunità di contribuire e sviluppare ulteriormente la piattaforma. Nel 2015, \textbf{Druid} è diventato un progetto \gls{open source}{} ufficiale sotto l'autorità della \gls{Apache Software Foundation}{}.\\ 
\textbf{Apache Druid} è comunemente utilizzato come back-end per le GUI di applicazioni analitiche o
per \gls{api}{} altamente simultanee che richiedono aggregazioni veloci. \\
\textbf{Druid} è sviluppato in Java e Scala, rilasciato sotto licenza Apache 2.0. \\La versione attuale è la 27.0.0 rilasciata il 10 agosto 2023.\\
\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{images/componenti/logo_druid.png}
    \caption{Logo di Apache Druid}
    \label{fig:logo_druid}
\end{figure}
\pagebreak
\subsection{Casi d'uso}
\textbf{Apache Druid} viene utilizzato in tutti quegli scenari in cui è necessario analizzare grandi quantità di dati in tempo reale, in modo scalabile, con \gls{fault tolerance}{} e con la possibilità di effettuare query complesse ad alta efficienza.\\  
I principali campi di utilizzo di \textbf{Apache Druid} sono:
\begin{list}{*}
    \item \textbf{analisi dati in real-time e applicazioni dati}: \textbf{Apache Druid} viene ampliamente impiegato in sistemi di acquisizione dati in
    tempo reale, query rapide e tempo di attività. \textbf{Druid} viene utilizzato per alimentare GUI
    di applicazioni analitiche o per \gls{api}{} simultanee che necessitano di aggregazioni veloci, i migliori risultati 
    vengono ottenuti nell'analisi di dati di tipo evento;
    \item \item \textbf{elaborazione di metriche}: \textbf{Apache Druid} viene spesso utilizzato per effettuare misurazioni sul coinvolgimento degli
    utenti e il monitoraggio dei dati di test, calcolando metriche, conteggi finalizzati a elaborare tendenze su grandi moli di dati;
    \item \textbf{operazioni \gls{olap}{}}: \textbf{Apache Druid} viene utilizzato per accelerare l’esecuzione di query su grandi moli di dati e potenziare le applicazioni; è progettato per un’elevata concorrenza e query in meno di un secondo, alimentando
    l’esplorazione interattiva dei dati attraverso un’interfaccia utente.
\end{list}
\subsection{Architettura e funzionamento}
\textbf{Apache Druid} include molteplici configurazione sia su singolo nodo, che distribuito su un \gls{cluster}{}.\\
Le distribuzioni su singolo nodo sono ormai poco utilizzate, ma esistono altre configurazioni pensate per macchine con bassa disponibilità di 
CPU e memoria, come i \gls{container}{}.
\subsubsection{Distribuzione su cluster}
\textbf{Apache Druid} nasce come sistema distribuito (Figura \ref{fig:druid_architecture}), scalabile, tollerante ai guasti, compatibile con il cloud. \\
Inoltre una architettura di questo tipo un malfunzionamento di una componente non influisce immediatamente sulle altre.\\

In generale un \gls{cluster}{} di \textbf{Apache Druid} ospita i seguenti server: 
\begin{list}{*}
    \item \textbf{i server principali}: sono responsabili della gestione dei \gls{metadati}{} e delle esigenze di coordinamento del \gls{cluster}{}, possono essere collocati insieme sullo stesso server;
    \item \item \textbf{i server dati}: finalizzati a  gestire i dati effettivi all'interno \gls{cluster}{}, traggono grandi vantaggi da CPU, RAM e SSD;
    \item  \textbf{i server d'interrogazione}: chiamati anche \textbf{Druid Broker}, accettano le richieste e le distribuiscono al resto del cluster.
\end{list}
\begin{figure}[h]   
    \centering
    \includegraphics[width=0.9\textwidth]{images/componenti/druid_architectcture.png}
    \caption{Architettura di Apache Druid}
    \label{fig:druid_architecture}
\end{figure}
\pagebreak
\paragraph{I server principali} o \textbf{Master} gestiscono l’\gls{injection}{} e la disponibilità dei dati: sono i responsabili dell’avvio
di nuovi operazioni di \gls{injection}{} e del coordinamento della disponibilità dei dati sui \textbf{Data server}.\\
Ogni server mantiene una connessione con a un \textbf{Zookeeper} per le informazioni sul \gls{cluster}{} corrente.
I server \textbf{Master} eseguono al loro interno i seguenti processi:
\subparagraph{I Coordinator} hanno il compito di gestire la disponibilità dei dati dei \gls{cluster}{}, comunicano
agli \textbf{Historical} di caricare o rilasciare segmenti in base alle configurazioni, sono i 
responsabili del caricamento di nuovi segmenti, dell’eliminazione di segmenti obsoleti, della
garanzia che i segmenti siano replicati (caricati su più nodi \textbf{Historical} diversi) un
numero corretto  di volte e sia presente un bilanciamento dei segmenti
tra \textbf{Historical} per mantenere quest’ultimo caricato uniformemente.Il \textbf{Coordinator} ha anche una connessione a un database
contenente l’elenco dei segmenti utilizzati. 
\subparagraph{Gli Overlord} sono i responsabili dell’accettazione delle attività, del coordinamento della distribuzione delle
attività, della restituzione degli stati ai
chiamanti. Possono essere eseguiti sia in modalità locale che su server dedicato. Gli \textbf{Overlord} hanno anche il compito di 
creare i \textbf{Peon} per l'esecuzione delle attività. 
\paragraph{I Server dati} eseguono le attività d'acquisizione e archiviazione dei dati interrogabili.
I server \textbf{dati} eseguono al loro interno i seguenti processi:
\subparagraph{Gli Historical} hanno il compito di copiare o estrarre i file di segmento dal \textbf{Deep Storage} al disco locale in un’area
chiamata $segment cache$ e di rispondere alle query su tali segmenti.
Il \textbf{Coordinator} controlla l’assegnazione dei segmenti agli \textbf{Historical} e il bilanciamento dei segmenti assegnati
a questi ultimi.\\ 
Gli \textbf{Historical} non comunicano direttamente tra loro, ne comunicano direttamente con il \textbf{Coordinator}. 
\subparagraph{I MiddleManager} 
hanno il compito di eseguire le attività di \gls{injection}{} e di indicizzazione dei dati.\\
Sono i responsabili dell'inserimento di nuovi dati all'interno del \gls{cluster}{}, della lettura di dati da fonti esterne e della pubblicazione di 
nuovi segmenti.\\
\subparagraph{I Peon} sono i motori di esecuzione delle attività generate dai processi \textbf{MiddleManager}. \\
Ogni \textbf{Peon} viene eseguito su una JVM separata ed è responsabile dell’esecuzione di una singola attività. 
Tutti i Peon che sono stati generati da un processo \textbf{MiddleManager} vengono eseguiti sullo stesso nodo.
\paragraph{I Server d'interrogazione} o Server query forniscono la funzionalità d'interazione con gli utenti, instradando le richieste  
ai \textbf{server dati} o ad altri \textbf{server query}, per la loro esecuzione. \\
I server query eseguono al loro interno i processi descritti di seguito.
\subparagraph{I Broker} sono i processi a cui instradare le query, analizzano i \gls{metadati}{} forniti
da \textbf{Zookeeper}, comprendono dove ricavare i dati necessari per elaborare i risultati delle query ed 
infine uniscono tutti i risultati elaborati per fornire un’unica risposta alla richiesta.\\
\subparagraph{I Router} sono i processi che hanno il compito di instradare le query a diversi processi \textbf{Broker}. Le query
vengono instradate in base alle regole di caricamento dei segmenti che vengono applicate.
Tale configurazione fornisce l’isolamento delle singole query, anche nel caso in cui si voglia applicare 
una priorità di esecuzione a determinate query.\\

\paragraph{Le dipendenze esterne}
Essendo \textbf{Apache Druid} un sistema distribuito e molto complesso, per il suo corretto funzionamento necessita di alcune dipendenze esterne.\\

\subparagraph{Deep storage}\label{sec:deep_storage}
\textbf{Apache Druid} memorizza i suoi dati e indici in file di segmenti partizionati in base al
tempo:  crea un segmento per ogni intervallo di tempo che contiene dati.\\
Affinchè \textbf{Druid} funzioni bene con un carichi di query elevati, è importante che la dimensione del file
del segmento rientri nell’intervallo consigliato di 300-700 MB. Se questo non accade è necessario valutare 
una modifica sulla configurazione di partizionamento dell’intervallo di tempo dei segmenti.\\
Il \textbf{deep storage} è il sistema nel quale vengono archiviati i segmenti.\\
Fino a che i processi di \textbf{Druid} possono vedere questa infrastruttura di archiviazione e accedere
ai segmenti archiviati su di essa, non si perderanno i dati indipendentemente dal numero
di nodi persi.\\
Ogni segmento viene creato da un \textbf{MiddleManager} come $mutable$ e $uncommitted$. \\
I dati sono interrogabili non appena vengono aggiunti a un segmento senza $commit$.
Periodicamente i segmenti vengono sottoposti a $commit$ e pubblicati in \textbf{deep storage} diventano immutabili, passando dal \textbf{MiddleManager} agli \textbf{Historical}.
\\Inoltre nel \textbf{Metadata storage} viene scritta una voce al segmento che lo descrive.\\
In generale si tratta di un sistema al di fuori di \textbf{Druid} può essere di due tipi:
\begin{list}{*}
\item 
\textbf{locale}: destinato a un solo server o a più server che hanno accesso ad un filesystem
condiviso;
\item \item \textbf{su cloud}: è più conveniente, scalabile e robusto, \textbf{Druid} è compatibile con diversi sistemi cloud come: Azure,
Amazon S3, Google.
\end{list}
\subparagraph{Zookeeper}
\textbf{Apache Druid} utilizza \textbf{Zookeeper} per la gestione dello stato corrente del cluster.\\
In \textbf{Zookeeper} avvengono le seguenti attività:
\begin{list}{*}
    \item elezione del servizio di coordinamento;
    \item protocollo di pubblicazione del segmento degli storici;
    \item protocollo di caricamento/rilascio del segmento tra \textbf{Coordinator} e \textbf{Historical};
    \item elezione del servizio di \textbf{Overlord};
    \item gestione delle attività di \textbf{Overlord} e \textbf{MiddleManager};
\end{list}
\subparagraph{Metadata storage} è l’archivio dove vengono conservati tutti i \gls{metadati}{} essenziali
per il funzionamento di un \gls{cluster}{} di \textbf{Apache Druid}, non viene utilizzato per archiviare i dati effettivi.\\
Nel caso di Druid, il \textbf{Metadata storage} viene spesso implementato utilizzando un database relazionale anche se non è l'unica soluzione possibile.\\ 
In generale contiene:
\begin{list}{*}
    \item \textbf{record dei segmenti}: memorizza i \gls{metadati}{} sui segmenti che dovrebbero
    essere disponibili nel sistema (chiamati anche segmenti usati);
    \item \item \textbf{record delle regole}: memorizza le varie regole su dove allocare e deallocare i segmenti del cluster;
    \item \textbf{record di configurazione}: memorizzare gli oggetti di configurazione
    di runtime, si tratta di un $feature$ futura e avrà lo scopo di modificare alcuni parametri di configurazione nel \gls{cluster}{} in
    fase di esecuzione.
\end{list}
\noindent
\\
In modalità predefinita \textbf{Apache Druid} utilizza \textbf{Derby}, ma database più adatti alla produzione
sono \textbf{MySQL} e \textbf{PostgreSQL}.
\subsection{Il modello dei dati}
\textbf{Apache Druid} memorizza i dati sotto forma di \gls{datasource}{} molto simili alle tabelle di un tradizionale database relazionale e alle serie temporali.
\\Il modello di dati di \textbf{Druid} presenta essenzialmente le seguenti componenti:
\begin{itemize}
    \item \textbf{timestamp principale}:  le \gls{datasource}{} di \textbf{Apache Druid}  devono sempre includere un $timestamp$ primario,  utilizzato per partizionare e ordinare i dati, per recuperare rapidamente i dati all'interno di un determinato intervallo di tempo;
    \item \textbf{dimensions}: sono colonne che \textbf{Druid} memorizza "così come sono"; possono utilizzare per qualsiasi scopo: filtrare, applicare aggregatori e così via;
    \item \textbf{metrics}: sono colonne che \textbf{Apache Druid} archivia in forma aggregata e diventano più utili se si utilizza la tecnica del rollup.
\end{itemize}
\pagebreak
\section{Streaming Data Pipelines}
\subsection{Introduzione}
Con il termine di \gls{Data Pipeline}{} si intende un software o un insieme di software che consentano il fluire automatico
di dati da un punto ad un altro del sistema posto in essere. 
Di solito, nella definizione di un sistema di questo tipo, le origini sono molteplici e generano
dati ad altissima velocità.\\
L’architettura che regge una \gls{Data Pipeline}{} consente di consumare, elaborare, archiviare
dati in tempo reale, man mano che vengono generati. Tale meccanismo consente di avere reazioni immediate ai dati processati. \\
Le tradizionali \gls{Data Pipeline}{} sono state progettate per elaborare dati statici, infatti prima estraggono, trasformano e poi caricano i dati per 
poterli poi utilizzare.\\
In generale in sistemi come \textbf{Apache Kafka} le pipeline dati tradizionali non sono più utilizzabili, considerando 
l' enorme mole di dati che sono tenute a processare.\\
\noindent
Per risolvere tale problema nelle Streaming \gls{Data Pipeline}{} si è andati a creare due livelli per l'elaborazione dei dati: 
\begin{list}{*}
    \item \textbf{archiviazione}: livello che consente la memorizzazione dei dati, permettendo letture e scritture a basso costo in termini computazionali mantenendo l’ordine di arrivo
    dei dati;
    \item \item \textbf{lavorazione}: livello che consente di elaborare e consumare i dati del livello di archiviazione andando a segnalare
    a quest’ultimo i dati non più necessari.
\end{list}

\subsection{Approccio utilizzato}\label{sec:approccio_utilizzato}
L'approccio comunemente utilizzato per la creazione di una Streaming \gls{Data Pipeline}{} è quello di utilizzare un \gls{message broker}{} come \textbf{Apache Kafka} e un sistema \gls{olap}{} come \textbf{Apache Druid} per l'analisi dati (Figura \ref{fig:data_pipeline}), operando nel seguente modo:\\
\begin{list}{*}
    \item \textbf{produzione dei dati}: all'interno dell'ambiente di sviluppo, i dati vengono prodotti da diverse fonti, sensori o applicazioni, e inviati al \gls{message broker}{} \textbf{Apache Kafka} 
    che ha il compito di archiviarli e successivamente distribuirli ai consumatori;
    \item \item \textbf{analisi dati}: i dati vengono letti dal \gls{message broker}{} \textbf{Apache Kafka} e inviati al sistema \gls{olap}{} \textbf{Apache Druid} che ha il compito di indicizzarli, elaborarli e renderli disponibili per eseguire query in tempo reale su di essi.
\end{list}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/componenti/SCHEMA_DATA_PIPELINE.png}
    \caption{Schema di una Streaming Data Pipeline con Apache Kafka e Apache Druid}
    \label{fig:data_pipeline}
\end{figure}
\clearpage
\newpage
\pagestyle{empty}
\null % o \mbox{} o \phantom{X}
\newpage