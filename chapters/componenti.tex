\chapter{Componenti di una Data Pipeline}\label{cap:Componenti di una Data Pipeline}
\section{Apache Kafka}
\subsection{Introduzione}
\textbf{Apache Kafka} è una piattaforma \gls{open source}{}, da Jay Kreps, Neha Narkhede e Jun Rao presso LinkedIn e successivamente donata alla \gls{Apache Software Foundation}{} nel 2011. (Figura \ref{fig:logo_kafka}).\\
\textbf{Apache Kafka} nasce con la necessità di LinkedIn di gestire grandi quantità di dati in tempo reale.\\ Già nel 2007 
Jay Kreps e il suo team si resero conto che le soluzioni allora attuali, basate su database tradizionali, non erano in grado di gestire 
un carico di lavoro crescente e la complessità del formato dei dati generati da LinkedIn.\\
Dunque per affrontare tale sfida, nel 2010 LinkedIn iniziò a utilizzare \textbf{Apache Kafka} per gestire i dati di log generati dai vari servizi. \\
Tale adozione ha dimostrato nel tempo che \textbf{Apache Kafka} è in grado di gestire carichi di lavoro molto elevati, di scalare facilmente e di garantire un elevato livello di affidabilità nella consegna di messaggi.\\ 
\textbf{Kafka} è scritto in Java e Scala e rilasciata sotto licenza Apache 2.0. La versione attuale è la 3.5.1 rilasciata il 21 luglio 2023.\\
\textbf{Kafka} nasce originariamente come \gls{message broker} e permette di gestire uno \gls{streaming di eventi}{} in tempo reale. \\ 
In particolare fornisce funzionalità per:
\begin{list}{*}{}
    \item pubblicare e sottoscrivere flussi di eventi, importandoli ed esportandoli da altri sistemi;
    \item archiviare tali flussi in modo affidabile e duraturo;
    \item elabora flussi di eventi in real time o in modo retrospettivo.
\end{list}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{images/componenti/logo_kafka.png}
    \caption{Logo di Apache Kafka}
    \label{fig:logo_kafka}
\end{figure}
\pagebreak
\subsection{Casi d'uso}
\textbf{Apache Kafka} viene ampliamente utilizzato in tutti quelli scenari in cui è richiesto la gestione 
affidabile di grandi quantità di dati in tempo reale.\\
I principali campi di utilizzo di \textbf{Apache Kafka} sono:
\begin{list}{*}
    \item \textbf{messagistica}: \textbf{Apache Kafka} viene particolarmente utilizzato come \gls{message broker}{}, in applicazioni di messaggistica 
    per disaccoppiare la produzione del messaggio dall'elaborazione dello stesso, \textbf{Kafka} rispetto ai tradizionali \gls{message broker}{} offre velocità e \gls{fault tolerance}{};
    \item \item \textbf{elaborazione del flusso dati}: è possibile anche utilizzare \textbf{Kafka} come componente principale per creare \gls{Data Pipeline}{} in cui i dati grezzi,
    provenienti da diverse sorgenti \textbf{Kafka} vengono aggregati, trasformati fino a ottenere un dato elaborato;
    \item \textbf{monitoraggio e analisi}: \textbf{Kafka} può essere utilizzato per raccogliere dati di monitoraggio provenienti da applicazioni, sistemi di controllo o siti web; 
    \item \textbf{archiviazione dei dati}: \textbf{Apache Kafka} può essere utilizzato come sistema di archiviazione dei dati a lungo termine, permettendo così analisi storiche e ripristino di sistemi 
    in caso di guasti;

\end{list}
    
\subsection{Architettura e funzionamento}
\textbf{Apache Kafka} nasce come sistema distribuito che opera su nodi (Figure \ref{fig:kafka_architecture}), i quali comunicano tramite protocollo o tramite protocollo
\gls{tcp}{} ad alte prestazioni.Data la sua natura distribuita implementa funzionalità di \gls{fault tolerance}{} con possibilità di rimpiazzo dei nodi che hanno avuto un malfunzionamento.\\  
\textbf{Kafka} può essere distribuito e utilizzato in vari modi tra cui \gls{virtual machine}{} e \gls{container}{}, \gls{on-promise}{}, o servizi cloud.\\
In generale \textbf{Apache Kafka} e costituito da due componenti essenziali: server e client.
\subsubsection{server}
\textbf{Kafka} viene eseguito come un cluster di uno o più server, che rivestono diversi ruoli. \\Alcuni svolgono la funzione di \textbf{Kafka Broker}: ricevono i messaggi dai produttori, li archiviano e inviano i messaggi ai rispettivi consumatori, al momento della sottoscrizione.
\\ Altri invece assolvono il compito di \textbf{Kafka Connect}: importano ed esportano i
dati sotto forma di flussi di eventi, permettendo così  d'interagire con altri sistemi esistenti.
\subsubsection{client}
I \textbf{client} sono un insieme di librerie che consentono di scrivere applicazioni distribuite e microservizi che permettono d'interagire con
il sistema di messaggistica di \textbf{Apache Kafka}, leggendo, scrivendo ed elaborando flussi di messaggi in parallelo, su larga scala e con \gls{fault tolerance}{} anche in caso di
problemi di rete o guasti della macchina.\\
In generale la scelta del client da utilizzare dipende dal linguaggio di programmazione che si vuole utilizzare per sviluppare l'applicazione.\\ 
\subsubsection{La struttura dei messaggi}
I messaggi inviati all'interno di \textbf{Apache Kafka} sono composti da una chiave, un valore e un timestamp. \\
Oltre a tali informazioni a ogni messaggio viene associato un \gls{topic} o argomento che permette di eseguire operazioni di organizzazione 
e filtraggio dei messaggi.\\
Un messaggio, una volta inviato a un consumatore non viene eliminato dal \gls{topic}{} ma viene mantenuto per un periodo di tempo configurabile attraverso un timeout (di default 7 giorni).\\
I \gls{topic}{} dei rispettivi messaggi vengono partizionati su più nodi per consentire a più consumatori di leggere gli stessi messaggi e permettendo ai client di leggere e scrivere messaggi da/a molti \gls{message broker}{}.\\
Quando un nuovo messaggio viene emesso, quest'ultimo si aggiunge alla rispettiva partizione relativa al \gls{topic}{} e viene assegnato un numero di offset che identifica il messaggio all'interno della partizione.\\
Grazie a tale meccanismo \textbf{Apache Kafka} garantisce che i messaggi vengano letti nell'ordine in cui sono stati scritti.
\subsubsection{Zookeeper}










\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{images/componenti/kafka_architetcture.png}
    \caption{Architettura di Apache Kafka}
    \label{fig:kafka_architecture}
\end{figure}

\subsection{Garanzie di funzionamento}
In \textbf{Kafka} esistono produttori e consumatori che producono e sottoscrivono eventi. Gli uni, essendo in un ambiente distribuito,
sono indipendenti l’uno dall’altro. \\
\textbf{Apache Kafka} in tale contesto può fornire una delle seguenti garanzie sulla consegna e ricezione dei messaggi:
\begin{list}{*}
    \item \textbf{at most once}: i messaggi vengono consegnati al consumatore al più una volta. In questo caso, i messaggi possono essere persi, ma non duplicati;
   \item \item  \textbf{at least once}: i messaggi vengono consegnati al consumatore almeno una volta, i messaggi possono essere duplicati, ma non persi;
    \item \textbf{exactly once}: i messaggi vengono consegnati al consumatore esattamente una volta. In questo caso, i messaggi non vengono né persi né duplicati, è la garanzia più costosa ma maggiormente richiesta.
\end{list}
\subsection{Politiche di retentions}


\section{Apache Druid}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{images/componenti/logo_druid.png}
    \caption{Logo di Apache Druid}
    \label{fig:logo_druid}
\end{figure}
\section{Streaming Data Pipelines}
\newpage
\pagestyle{empty}
\null % o \mbox{} o \phantom{X}
\newpage